# Migration Elasticsearch et Kibana

Guide complet pour migrer vos index Elasticsearch, dataviews et dashboards Kibana.

## ðŸ“‹ Sommaire

1. [Vue d'ensemble](#vue-densemble)
2. [Installation](#installation)
3. [Utilisation](#utilisation)
4. [Commandes disponibles](#commandes-disponibles)
5. [Format des exports](#format-des-exports)
6. [Exemples d'utilisation](#exemples-dutilisation)
7. [Architecture](#architecture)
8. [DÃ©pannage](#dÃ©pannage)

## ðŸŽ¯ Vue d'ensemble

Le script `scripts/migrate_elasticsearch.py` permet de:

- âœ… **Exporter/Importer les index Elasticsearch**
  - Mappings complets (types, analyseurs, settings)
  - Documents (format NDJSON pour bulk import)
  - Support du Scroll API pour grandes volumÃ©tries

- âœ… **Exporter/Importer les dataviews Kibana**
  - Index patterns avec tous les champs
  - Configurations et formatters

- âœ… **Exporter/Importer les dashboards Kibana**
  - Dashboards avec panneaux
  - Visualisations associÃ©es
  - DÃ©pendances prÃ©servÃ©es

- âœ… **Backup/Restore complets**
  - Sauvegarde timestampÃ©e
  - Statistiques d'export/import
  - Gestion d'erreurs dÃ©taillÃ©e

## ðŸ“¦ Installation

### PrÃ©requis

- Python 3.8+
- Elasticsearch 7.x ou 8.x
- Kibana 7.x ou 8.x

### DÃ©pendances

```bash
# Installation des dÃ©pendances
uv pip install elasticsearch requests

# Ou avec pip standard
pip install elasticsearch requests
```

### VÃ©rification

```bash
# VÃ©rifier que le script est exÃ©cutable
python scripts/migrate_elasticsearch.py --help
```

## ðŸš€ Utilisation

### Commande de base

```bash
python scripts/migrate_elasticsearch.py <commande> [options]
```

### Options communes

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--es-host` | HÃ´te Elasticsearch (host:port) | localhost:9200 |
| `--kibana-host` | HÃ´te Kibana (host:port) | localhost:5601 |
| `--username` | Nom d'utilisateur (optionnel) | None |
| `--password` | Mot de passe (optionnel) | None |

## ðŸ“š Commandes disponibles

### 1. Export complet

Export tous les Ã©lÃ©ments (index + dataviews + dashboards):

```bash
python scripts/migrate_elasticsearch.py export --output ./backup
```

**Sortie**:
```
ðŸ“¦ Export des index Elasticsearch...
  â†’ Export de l'index: ml-api-logs-predictions
    âœ“ Mapping sauvegardÃ©: ./backup/backup_20250121_153000/indexes/ml-api-logs-predictions_mapping.json
    âœ“ 1523 documents exportÃ©s: ./backup/backup_20250121_153000/indexes/ml-api-logs-predictions_documents.ndjson

ðŸ“Š Export des dataviews Kibana...
  âœ“ Dataview exportÃ©: ml-api-logs-*

ðŸ“ˆ Export des dashboards Kibana...
  âœ“ Dashboard exportÃ©: ML API - Monitoring Dashboard
  âœ“ Visualisation exportÃ©e: Predictions per hour

âœ… Export complet terminÃ©!
ðŸ“ Backup sauvegardÃ© dans: ./backup/backup_20250121_153000
ðŸ“Š Statistiques: ./backup/backup_20250121_153000/migration_stats.json
```

### 2. Import complet

Import tous les Ã©lÃ©ments depuis un backup:

```bash
python scripts/migrate_elasticsearch.py import \
  --input ./backup/backup_20250121_153000
```

### 3. Export uniquement les index

Export les index Elasticsearch sans les Ã©lÃ©ments Kibana:

```bash
python scripts/migrate_elasticsearch.py export-indexes --output ./backup
```

**Filtrage par pattern**:
```bash
# Le script exporte par dÃ©faut les index ml-api-*
# Pour personnaliser, modifier le code ligne 106
```

### 4. Import uniquement les index

Import les index depuis un backup:

```bash
python scripts/migrate_elasticsearch.py import-indexes \
  --input ./backup/backup_20250121_153000
```

### 5. Export uniquement les dataviews

Export les dataviews (index patterns) Kibana:

```bash
python scripts/migrate_elasticsearch.py export-dataviews --output ./backup
```

### 6. Import uniquement les dataviews

Import les dataviews depuis un backup:

```bash
python scripts/migrate_elasticsearch.py import-dataviews \
  --input ./backup/backup_20250121_153000
```

### 7. Export uniquement les dashboards

Export les dashboards et visualisations Kibana:

```bash
python scripts/migrate_elasticsearch.py export-dashboards --output ./backup
```

### 8. Import uniquement les dashboards

Import les dashboards depuis un backup:

```bash
python scripts/migrate_elasticsearch.py import-dashboards \
  --input ./backup/backup_20250121_153000
```

## ðŸ“‚ Format des exports

### Structure du backup

```
backup_20250121_153000/
â”œâ”€â”€ migration_stats.json          # Statistiques globales
â”œâ”€â”€ indexes/                       # Index Elasticsearch
â”‚   â”œâ”€â”€ ml-api-logs-predictions_mapping.json
â”‚   â”œâ”€â”€ ml-api-logs-predictions_documents.ndjson
â”‚   â”œâ”€â”€ ml-api-logs-requests_mapping.json
â”‚   â”œâ”€â”€ ml-api-logs-requests_documents.ndjson
â”‚   â”œâ”€â”€ ml-api-logs-errors_mapping.json
â”‚   â”œâ”€â”€ ml-api-logs-errors_documents.ndjson
â”‚   â”œâ”€â”€ ml-api-top-func_mapping.json
â”‚   â””â”€â”€ ml-api-top-func_documents.ndjson
â”œâ”€â”€ dataviews/                     # Dataviews Kibana
â”‚   â”œâ”€â”€ ml-api-logs-*.json
â”‚   â””â”€â”€ ml-api-errors-*.json
â””â”€â”€ dashboards/                    # Dashboards Kibana
    â”œâ”€â”€ dashboard-1234.json
    â”œâ”€â”€ dashboard-5678.json
    â””â”€â”€ visualizations/            # Visualisations associÃ©es
        â”œâ”€â”€ viz-abc.json
        â””â”€â”€ viz-def.json
```

### Format NDJSON pour les documents

Format utilisÃ©: **Newline Delimited JSON** (NDJSON)

```json
{"index":{"_index":"ml-api-logs-predictions","_id":"doc-1"}}
{"timestamp":"2025-01-21T15:30:00Z","prediction":1,"probability":0.85}
{"index":{"_index":"ml-api-logs-predictions","_id":"doc-2"}}
{"timestamp":"2025-01-21T15:31:00Z","prediction":0,"probability":0.23}
```

Ce format est optimisÃ© pour le bulk import Elasticsearch.

### Fichier migration_stats.json

```json
{
  "timestamp": "20250121_153000",
  "backup_dir": "./backup/backup_20250121_153000",
  "indexes": {
    "exported": 4,
    "documents": 15234,
    "errors": []
  },
  "dataviews": {
    "exported": 2,
    "errors": []
  },
  "dashboards": {
    "exported": 8,
    "errors": []
  }
}
```

## ðŸ”§ Exemples d'utilisation

### Exemple 1: Migration complÃ¨te local â†’ production

```bash
# 1. Export depuis l'environnement local
python scripts/migrate_elasticsearch.py export \
  --output ./backup \
  --es-host localhost:9200 \
  --kibana-host localhost:5601

# 2. Copier le backup vers le serveur de production
scp -r ./backup/backup_20250121_153000 user@production:/tmp/

# 3. Import sur la production
ssh user@production
cd /path/to/project
python scripts/migrate_elasticsearch.py import \
  --input /tmp/backup_20250121_153000 \
  --es-host production:9200 \
  --kibana-host production:5601 \
  --username elastic \
  --password changeme
```

### Exemple 2: Backup quotidien automatisÃ©

CrÃ©er un script `backup_daily.sh`:

```bash
#!/bin/bash
# Backup quotidien Elasticsearch + Kibana

BACKUP_DIR="/data/backups/elasticsearch"
RETENTION_DAYS=30

# Export
python scripts/migrate_elasticsearch.py export \
  --output "$BACKUP_DIR" \
  --es-host localhost:9200 \
  --kibana-host localhost:5601

# Nettoyer les anciens backups (>30 jours)
find "$BACKUP_DIR" -type d -name "backup_*" -mtime +$RETENTION_DAYS -exec rm -rf {} \;

echo "âœ… Backup terminÃ©: $(date)"
```

Ajouter Ã  crontab:
```bash
# Backup tous les jours Ã  2h du matin
0 2 * * * /path/to/backup_daily.sh >> /var/log/elasticsearch_backup.log 2>&1
```

### Exemple 3: Migration sÃ©lective (seulement les index)

```bash
# Exporter uniquement les index (sans dataviews/dashboards)
python scripts/migrate_elasticsearch.py export-indexes \
  --output ./backup_indexes

# Importer uniquement les index
python scripts/migrate_elasticsearch.py import-indexes \
  --input ./backup_indexes \
  --es-host production:9200
```

### Exemple 4: Restauration aprÃ¨s incident

```bash
# 1. Identifier le dernier backup
ls -lt /data/backups/elasticsearch/

# 2. Restauration complÃ¨te
python scripts/migrate_elasticsearch.py import \
  --input /data/backups/elasticsearch/backup_20250121_020000 \
  --es-host localhost:9200 \
  --kibana-host localhost:5601

# 3. VÃ©rifier l'import
curl http://localhost:9200/_cat/indices?v
```

### Exemple 5: Migration avec authentification

```bash
# Export depuis cluster sÃ©curisÃ©
python scripts/migrate_elasticsearch.py export \
  --output ./backup \
  --es-host cluster.example.com:9200 \
  --kibana-host cluster.example.com:5601 \
  --username admin \
  --password super_secret_password
```

## ðŸ—ï¸ Architecture

### Classe ElasticsearchMigrator

```python
class ElasticsearchMigrator:
    def __init__(self, es_host, kibana_host, username, password):
        """Initialise les connexions ES et Kibana."""

    def export_indexes(self, output_dir, index_patterns=None):
        """Export index avec Scroll API."""

    def import_indexes(self, input_dir):
        """Import index avec Bulk API."""

    def export_dataviews(self, output_dir):
        """Export dataviews via Kibana API."""

    def import_dataviews(self, input_dir):
        """Import dataviews via Kibana API."""

    def export_dashboards(self, output_dir):
        """Export dashboards + visualizations."""

    def import_dashboards(self, input_dir):
        """Import dashboards + visualizations."""

    def export_all(self, output_dir):
        """Export complet avec timestamp."""

    def import_all(self, input_dir):
        """Import complet."""
```

### APIs utilisÃ©es

| OpÃ©ration | API Elasticsearch/Kibana |
|-----------|-------------------------|
| RÃ©cupÃ©rer mapping | `GET /{index}` |
| RÃ©cupÃ©rer documents | `POST /{index}/_search` avec scroll |
| Bulk insert | `POST /_bulk` |
| Liste dataviews | `GET /api/saved_objects/_find?type=index-pattern` |
| CrÃ©er dataview | `POST /api/saved_objects/index-pattern/{id}` |
| Liste dashboards | `GET /api/saved_objects/_find?type=dashboard` |
| CrÃ©er dashboard | `POST /api/saved_objects/dashboard/{id}` |

### Gestion des grandes volumÃ©tries

Le script utilise le **Scroll API** d'Elasticsearch pour paginer les rÃ©sultats:

```python
# Scroll de 2 minutes, batch de 1000 documents
response = es.search(
    index=index_name,
    scroll='2m',
    size=1000,
    body={"query": {"match_all": {}}}
)

scroll_id = response['_scroll_id']
hits = response['hits']['hits']

while hits:
    # Traiter le batch
    for hit in hits:
        process_document(hit)

    # RÃ©cupÃ©rer le batch suivant
    response = es.scroll(scroll_id=scroll_id, scroll='2m')
    hits = response['hits']['hits']

# Nettoyer le scroll
es.clear_scroll(scroll_id=scroll_id)
```

### Bulk Import optimisÃ©

Import par batch de 1000 documents:

```python
batch = []
for i in range(0, len(lines), 2):
    batch.append(lines[i])      # Metadata
    batch.append(lines[i + 1])  # Document

    # Bulk insert tous les 1000 docs
    if len(batch) >= 2000:  # 2 lignes par doc
        es.bulk(body=''.join(batch), refresh=True)
        batch = []

# Dernier batch
if batch:
    es.bulk(body=''.join(batch), refresh=True)
```

## ðŸ› DÃ©pannage

### Erreur: Connection refused

**ProblÃ¨me**: Impossible de se connecter Ã  Elasticsearch/Kibana

**Solutions**:
```bash
# VÃ©rifier qu'Elasticsearch est dÃ©marrÃ©
curl http://localhost:9200/_cluster/health

# VÃ©rifier que Kibana est dÃ©marrÃ©
curl http://localhost:5601/api/status

# VÃ©rifier les ports utilisÃ©s
netstat -an | grep 9200
netstat -an | grep 5601
```

### Erreur: Authentication required

**ProblÃ¨me**: Le cluster nÃ©cessite une authentification

**Solution**:
```bash
# Ajouter les credentials
python scripts/migrate_elasticsearch.py export \
  --output ./backup \
  --username elastic \
  --password changeme
```

### Erreur: Index already exists

**ProblÃ¨me**: L'index existe dÃ©jÃ  sur la destination

**Solution**: Le script supprime automatiquement l'index existant avant l'import.

Si vous souhaitez Ã©viter la suppression, commentez les lignes 211-214 dans le script:
```python
# if self.es.indices.exists(index=index_name):
#     print(f"    âš ï¸  Index {index_name} existe dÃ©jÃ , suppression...")
#     self.es.indices.delete(index=index_name)
```

### Erreur: Scroll timeout

**ProblÃ¨me**: Le scroll expire avant la fin de l'export

**Solution**: Augmenter le timeout du scroll (ligne 135):
```python
# De 2m Ã  5m
response = self.es.search(
    index=index_name,
    scroll='5m',  # Au lieu de '2m'
    size=1000,
    body={"query": {"match_all": {}}}
)
```

### Erreur: Heap overflow sur gros volumes

**ProblÃ¨me**: MÃ©moire insuffisante pour l'export

**Solutions**:

1. **RÃ©duire la taille des batchs** (ligne 136):
```python
size=500,  # Au lieu de 1000
```

2. **Augmenter la heap Java d'Elasticsearch**:
```bash
# Dans /etc/elasticsearch/jvm.options
-Xms4g
-Xmx4g
```

3. **Export index par index**:
```bash
# Exporter chaque index sÃ©parÃ©ment
python scripts/migrate_elasticsearch.py export-indexes \
  --output ./backup_index1

# Modifier le code pour filtrer un seul index (ligne 106)
index_patterns = ["ml-api-logs-predictions"]  # Un seul index
```

### Erreur: Kibana API returns 404

**ProblÃ¨me**: L'API Kibana n'est pas accessible

**Solution**: VÃ©rifier la version de Kibana et ajuster les URLs si nÃ©cessaire.

Pour Kibana 8.x, les endpoints peuvent changer:
```python
# Kibana 7.x
url = f"{self.kibana_url}/api/saved_objects/_find"

# Kibana 8.x (si problÃ¨me)
url = f"{self.kibana_url}/api/saved_objects/_find?spaces=*"
```

### Performances lentes

**Optimisations**:

1. **DÃ©sactiver refresh pendant le bulk import**:
```python
es.bulk(body=''.join(batch), refresh=False)  # Pas de refresh
```

2. **Augmenter la taille des batchs**:
```python
size=2000,  # Au lieu de 1000
```

3. **DÃ©sactiver les replicas pendant l'import**:
```bash
# Avant l'import
curl -X PUT "localhost:9200/ml-api-*/_settings" -H 'Content-Type: application/json' -d'
{
  "index": {
    "number_of_replicas": 0
  }
}'

# AprÃ¨s l'import
curl -X PUT "localhost:9200/ml-api-*/_settings" -H 'Content-Type: application/json' -d'
{
  "index": {
    "number_of_replicas": 1
  }
}'
```

## ðŸ“Š Monitoring et logs

### Activer le mode verbose

Modifier le script pour ajouter des logs dÃ©taillÃ©s:

```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
```

### Statistiques d'export/import

Le fichier `migration_stats.json` contient toutes les statistiques:

```bash
# Afficher les statistiques
cat ./backup/backup_20250121_153000/migration_stats.json | python -m json.tool

# Exemple de sortie
{
  "timestamp": "20250121_153000",
  "backup_dir": "./backup/backup_20250121_153000",
  "indexes": {
    "exported": 4,
    "documents": 15234,
    "errors": []
  },
  "dataviews": {
    "exported": 2,
    "errors": []
  },
  "dashboards": {
    "exported": 8,
    "errors": []
  }
}
```

### VÃ©rification post-migration

```bash
# Comparer le nombre de documents
curl -X GET "localhost:9200/ml-api-logs-predictions/_count"

# VÃ©rifier les mappings
curl -X GET "localhost:9200/ml-api-logs-predictions/_mapping?pretty"

# Lister les dataviews Kibana
curl -X GET "localhost:5601/api/saved_objects/_find?type=index-pattern" \
  -H 'kbn-xsrf: true'

# Lister les dashboards
curl -X GET "localhost:5601/api/saved_objects/_find?type=dashboard" \
  -H 'kbn-xsrf: true'
```

## ðŸ”’ SÃ©curitÃ©

### Bonnes pratiques

1. **Ne jamais commiter les credentials**:
```bash
# Utiliser des variables d'environnement
export ES_USERNAME=elastic
export ES_PASSWORD=changeme

python scripts/migrate_elasticsearch.py export \
  --output ./backup \
  --username "$ES_USERNAME" \
  --password "$ES_PASSWORD"
```

2. **Chiffrer les backups sensibles**:
```bash
# Chiffrer le backup avec GPG
tar -czf - ./backup/backup_20250121_153000 | \
  gpg --symmetric --cipher-algo AES256 > backup.tar.gz.gpg

# DÃ©chiffrer
gpg --decrypt backup.tar.gz.gpg | tar -xzf -
```

3. **Restreindre les permissions**:
```bash
# Seulement le propriÃ©taire peut lire/Ã©crire
chmod 700 ./backup/
```

4. **Utiliser HTTPS en production**:
```python
# Modifier le script pour utiliser HTTPS
self.es = Elasticsearch(
    [f"https://{es_host}"],  # HTTPS au lieu de HTTP
    basic_auth=(username, password),
    verify_certs=True,
    ca_certs="/path/to/ca.crt"
)
```

## ðŸ“š Ressources

- [Elasticsearch Bulk API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html)
- [Elasticsearch Scroll API](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#scroll-search-results)
- [Kibana Saved Objects API](https://www.elastic.co/guide/en/kibana/current/saved-objects-api.html)
- [Script de migration](../scripts/migrate_elasticsearch.py)

---

**DerniÃ¨re mise Ã  jour**: 2025-01-21
**Version**: 1.0.0
