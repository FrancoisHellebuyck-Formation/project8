# Pipeline d'Int√©gration des Logs

## Vue d'ensemble

Ce document d√©crit l'architecture compl√®te du pipeline d'int√©gration des logs, permettant la collecte, le filtrage et l'indexation des logs de l'API ML dans Elasticsearch pour analyse et monitoring.

## Table des mati√®res

- [Architecture Globale](#architecture-globale)
- [Composants du Pipeline](#composants-du-pipeline)
- [Flux de Donn√©es](#flux-de-donn√©es)
- [Sources de Logs](#sources-de-logs)
- [Indexation Multiple](#indexation-multiple)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Monitoring](#monitoring)

## Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SOURCES DE LOGS                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    Redis (API logs)    ‚îÇ  Gradio (/logs_api endpoint)          ‚îÇ
‚îÇ    Port 6379           ‚îÇ  HuggingFace Spaces                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   COLLECTOR     ‚îÇ
                    ‚îÇ  collector.py   ‚îÇ
                    ‚îÇ                 ‚îÇ
                    ‚îÇ  - Connexion    ‚îÇ
                    ‚îÇ  - R√©cup√©ration ‚îÇ
                    ‚îÇ  - D√©duplication‚îÇ
                    ‚îÇ  - Parsing JSON ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ     FILTER      ‚îÇ
                    ‚îÇ    filter.py    ‚îÇ
                    ‚îÇ                 ‚îÇ
                    ‚îÇ  - Pattern match‚îÇ
                    ‚îÇ  - HTTP method  ‚îÇ
                    ‚îÇ  - Validation   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ           INDEXER                   ‚îÇ
                    ‚îÇ          indexer.py                 ‚îÇ
                    ‚îÇ                                     ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                    ‚îÇ  ‚îÇ  ALL_DOCUMENTS (non filtr√©s)  ‚îÇ ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                    ‚îÇ              ‚Üì                      ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                    ‚îÇ  ‚îÇ    ml-api-logs (TOUS)         ‚îÇ ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                    ‚îÇ                                     ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                    ‚îÇ  ‚îÇ FILTERED_DOCUMENTS (filtr√©s)  ‚îÇ ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                    ‚îÇ         ‚Üì              ‚Üì            ‚îÇ
                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                    ‚îÇ  ‚îÇml-api-message‚îÇ ‚îÇml-api-perfs ‚îÇ ‚îÇ
                    ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ              ‚îÇ ‚îÇ
                    ‚îÇ  ‚îÇml-api-top-  ‚îÇ ‚îÇ              ‚îÇ ‚îÇ
                    ‚îÇ  ‚îÇ   func      ‚îÇ ‚îÇ              ‚îÇ ‚îÇ
                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  ELASTICSEARCH  ‚îÇ
                    ‚îÇ  Port 9200      ‚îÇ
                    ‚îÇ  4 index cr√©√©s  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    KIBANA       ‚îÇ
                    ‚îÇ  Port 5601      ‚îÇ
                    ‚îÇ  Visualisation  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Composants du Pipeline

### 1. Collector (`src/logs_pipeline/collector.py`)

**Responsabilit√©s** :
- Connexion aux sources de logs (Redis ou Gradio)
- R√©cup√©ration des logs bruts
- D√©duplication bas√©e sur le timestamp
- Parsing JSON et validation

**Classe principale** :
```python
class LogCollector:
    def __init__(self, source: str = "redis"):
        """
        Args:
            source: "redis" ou "gradio"
        """

    def fetch_logs(self, limit: int = 100) -> List[Dict]:
        """R√©cup√®re les logs depuis la source."""

    def parse_log_entry(self, log_entry: str) -> Optional[Dict]:
        """Parse une entr√©e de log JSON."""
```

**Sources support√©es** :

| Source | Description | Configuration |
|--------|-------------|---------------|
| `redis` | Cache Redis local | `REDIS_HOST`, `REDIS_PORT` |
| `gradio` | API Gradio HF Spaces | `GRADIO_URL` |

**Exemple d'utilisation** :
```python
# Mode Redis
collector = LogCollector(source="redis")
logs = collector.fetch_logs(limit=100)

# Mode Gradio
collector = LogCollector(source="gradio")
logs = collector.fetch_logs(limit=100)
```

### 2. Filter (`src/logs_pipeline/filter.py`)

**Responsabilit√©s** :
- Filtrage par pattern (regex)
- Filtrage par m√©thode HTTP
- Extraction des donn√©es structur√©es
- Validation des champs requis

**Classe principale** :
```python
class LogFilter:
    def __init__(self, pattern: str = "API Call - POST /predict"):
        """
        Args:
            pattern: Pattern regex pour filtrer les logs
        """

    def filter_logs(self, logs: List[Dict]) -> List[Dict]:
        """Filtre les logs selon le pattern."""

    def extract_performance_metrics(self, log: Dict) -> Optional[Dict]:
        """Extrait les m√©triques de performance."""
```

**Patterns de filtrage** :

| Pattern | Description |
|---------|-------------|
| `API Call - POST /predict` | Logs de pr√©diction |
| `API Call - POST /predict_proba` | Logs de probabilit√©s |
| `Performance metrics` | M√©triques uniquement |

**Exemple d'utilisation** :
```python
log_filter = LogFilter(pattern="API Call - POST /predict")
filtered_logs = log_filter.filter_logs(raw_logs)
```

### 3. Indexer (`src/logs_pipeline/indexer.py`)

**Responsabilit√©s** :
- Connexion √† Elasticsearch
- Cr√©ation et gestion des index
- Indexation en batch (bulk)
- Gestion des erreurs d'indexation

**Classe principale** :
```python
class ElasticsearchIndexer:
    def __init__(self, host: str = "localhost", port: int = 9200):
        """
        Args:
            host: Host Elasticsearch
            port: Port Elasticsearch
        """

    def create_index(self, index_name: str, mapping: Dict):
        """Cr√©e un index avec mapping."""

    def index_logs(self, index_name: str, logs: List[Dict]) -> Dict:
        """Indexe les logs en batch."""

    def get_index_stats(self, index_name: str) -> Dict:
        """R√©cup√®re les statistiques d'un index."""
```

**Index cr√©√©s** :

| Index | Description | Documents |
|-------|-------------|-----------|
| `ml-api-logs` | Tous les logs bruts | ALL |
| `ml-api-message` | Logs avec donn√©es de pr√©diction | FILTERED |
| `ml-api-perfs` | Logs avec m√©triques de performance | FILTERED |
| `ml-api-top-func` | Top fonctions co√ªteuses | FILTERED |

**Exemple d'utilisation** :
```python
indexer = ElasticsearchIndexer(host="localhost", port=9200)

# Indexer tous les logs
indexer.index_logs("ml-api-logs", all_logs)

# Indexer les logs filtr√©s
indexer.index_logs("ml-api-message", filtered_logs)
indexer.index_logs("ml-api-perfs", filtered_logs)
```

### 4. Pipeline Orchestrator (`src/logs_pipeline/pipeline.py`)

**Responsabilit√©s** :
- Orchestration du pipeline complet
- Gestion des erreurs
- Logging du processus
- Statistiques d'ex√©cution

**Classe principale** :
```python
class LogPipeline:
    def __init__(
        self,
        source: str = "redis",
        es_host: str = "localhost",
        es_port: int = 9200,
        batch_size: int = 100
    ):
        """Initialise le pipeline."""

    def run_once(self) -> Dict:
        """Ex√©cute le pipeline une seule fois."""

    def run_continuous(self, interval: int = 10):
        """Ex√©cute le pipeline en continu."""
```

**Exemple d'utilisation** :
```python
# Ex√©cution unique
pipeline = LogPipeline(source="redis")
stats = pipeline.run_once()

# Ex√©cution continue (toutes les 10 secondes)
pipeline.run_continuous(interval=10)
```

## Flux de Donn√©es

### Flux 1 : Pipeline Complet (Mode Normal)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  API Request ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 1. G√©n√©ration log
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Redis Cache  ‚îÇ
‚îÇ (api_logs)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 2. Collecte (poll)
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Collector   ‚îÇ
‚îÇ  - Fetch     ‚îÇ
‚îÇ  - Parse     ‚îÇ
‚îÇ  - Dedupe    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 3. Documents bruts
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Filter     ‚îÇ
‚îÇ  - Pattern   ‚îÇ
‚îÇ  - Extract   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 4. Documents filtr√©s + tous
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Indexer             ‚îÇ
‚îÇ                          ‚îÇ
‚îÇ  all_docs ‚Üí ml-api-logs  ‚îÇ
‚îÇ                          ‚îÇ
‚îÇ  filtered_docs ‚Üí         ‚îÇ
‚îÇ    ml-api-message        ‚îÇ
‚îÇ    ml-api-perfs          ‚îÇ
‚îÇ    ml-api-top-func       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 5. Bulk insert
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇElasticsearch ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux 2 : Mode Gradio (HuggingFace Spaces)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Gradio Space    ‚îÇ
‚îÇ  (Port 7860)     ‚îÇ
‚îÇ                  ‚îÇ
‚îÇ  /logs_api       ‚îÇ
‚îÇ  endpoint        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 1. HTTP GET request
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Collector   ‚îÇ
‚îÇ  (gradio)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 2. JSON logs
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Filter     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 3. Filtered docs
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Indexer    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 4. Bulk insert
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇElasticsearch ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux 3 : D√©duplication

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Collector                  ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  seen_timestamps = set()            ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  for log in raw_logs:               ‚îÇ
‚îÇ    timestamp = log["timestamp"]     ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ    if timestamp in seen_timestamps: ‚îÇ
‚îÇ      skip  # ‚ùå Doublon             ‚îÇ
‚îÇ    else:                            ‚îÇ
‚îÇ      seen_timestamps.add(timestamp) ‚îÇ
‚îÇ      process  # ‚úÖ Nouveau          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Sources de Logs

### Source 1 : Redis (Mode Local/Docker)

**Configuration** :
```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_LOGS_KEY=api_logs
```

**Avantages** :
- Latence faible
- Acc√®s direct local
- Pas de d√©pendance r√©seau

**Inconv√©nients** :
- N√©cessite Redis actif
- Logs volatils (max 1000)

**Structure des logs Redis** :
```json
{
  "timestamp": "2025-11-22T10:30:45.123456",
  "level": "INFO",
  "message": "[uuid] POST /predict - 200 - 45ms - input - result",
  "data": {
    "transaction_id": "550e8400-e29b-41d4-a716-446655440000",
    "input_data": {
      "AGE": 65,
      "GENDER": 1,
      "SMOKING": 1,
      ...
    },
    "result": {
      "prediction": 1,
      "probability": 0.85,
      "message": "YES - High probability"
    },
    "performance_metrics": {
      "inference_time_ms": 12.5,
      "cpu_time_ms": 8.3,
      "memory_mb": 245.6,
      ...
    }
  }
}
```

### Source 2 : Gradio (Mode HuggingFace Spaces)

**Configuration** :
```bash
GRADIO_URL=https://francoisformation-oc-project8.hf.space
```

**Avantages** :
- Acc√®s √† distance
- Pas de Redis n√©cessaire
- Logs persistants

**Inconv√©nients** :
- Latence r√©seau
- D√©pendance HF Spaces
- Rate limiting possible

**Endpoint** :
```
GET {GRADIO_URL}/logs_api?limit=100&offset=0
```

**R√©ponse** :
```json
{
  "logs": [
    {
      "timestamp": "...",
      "level": "INFO",
      "message": "...",
      "data": {...}
    }
  ],
  "total": 523,
  "limit": 100,
  "offset": 0
}
```

## Indexation Multiple

### Index 1 : ml-api-logs (Tous les logs)

**Objectif** : Conservation de TOUS les logs sans filtrage

**Mapping** :
```json
{
  "mappings": {
    "properties": {
      "timestamp": {"type": "date"},
      "level": {"type": "keyword"},
      "message": {"type": "text"},
      "data": {"type": "object", "enabled": true}
    }
  }
}
```

**Cas d'usage** :
- D√©bogage complet
- Audit
- Recherche full-text
- Analyse des erreurs

### Index 2 : ml-api-message (Pr√©dictions)

**Objectif** : Logs filtr√©s contenant les donn√©es de pr√©diction

**Champs extraits** :
```python
{
  "timestamp": "2025-11-22T10:30:45.123456",
  "transaction_id": "uuid",
  "input_data": {
    "AGE": 65,
    "GENDER": 1,
    "SMOKING": 1,
    # ... 14 features
  },
  "result": {
    "prediction": 1,
    "probability": 0.85,
    "message": "YES - High probability"
  }
}
```

**Cas d'usage** :
- Analyse du drift de donn√©es
- Distribution des pr√©dictions
- Analyse des patterns de patients

### Index 3 : ml-api-perfs (M√©triques de Performance)

**Objectif** : Logs filtr√©s contenant les m√©triques de performance

**Champs extraits** :
```python
{
  "timestamp": "2025-11-22T10:30:45.123456",
  "transaction_id": "uuid",
  "inference_time_ms": 12.5,
  "cpu_time_ms": 8.3,
  "memory_mb": 245.6,
  "memory_delta_mb": 2.3,
  "function_calls": 42,
  "latency_ms": 45.2
}
```

**Cas d'usage** :
- Optimisation du mod√®le
- D√©tection de d√©gradation
- Alerting sur latence
- Analyse de throughput

### Index 4 : ml-api-top-func (Profiling Fonctions)

**Objectif** : Top fonctions co√ªteuses par transaction

**Champs extraits** :
```python
{
  "timestamp": "2025-11-22T10:30:45.123456",
  "transaction_id": "uuid",
  "function_name": "predict",
  "cumulative_time": 8.5,
  "calls": 1,
  "filename": "predictor.py",
  "line_number": 42
}
```

**Cas d'usage** :
- Profiling d√©taill√©
- Optimisation du code
- D√©tection de bottlenecks
- Code review

## Configuration

### Variables d'Environnement

```bash
# Source des logs
PIPELINE_SOURCE=redis  # ou "gradio"

# Configuration Redis (si source=redis)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_LOGS_KEY=api_logs

# Configuration Gradio (si source=gradio)
GRADIO_URL=https://francoisformation-oc-project8.hf.space

# Configuration Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_INDEX=ml-api-logs  # Index de base

# Configuration Pipeline
PIPELINE_BATCH_SIZE=100
PIPELINE_POLL_INTERVAL=10
PIPELINE_FILTER_PATTERN=API Call - POST /predict
```

### Fichier de Configuration

Fichier : `.env`

```bash
# Pipeline de logs
PIPELINE_BATCH_SIZE=100
PIPELINE_POLL_INTERVAL=10
PIPELINE_FILTER_PATTERN=API Call - POST /predict

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_INDEX=ml-api-logs

# Gradio (optionnel)
GRADIO_URL=https://francoisformation-oc-project8.hf.space
```

## Utilisation

### Mode 1 : Ex√©cution Unique

```bash
# Depuis Redis
make pipeline-once

# √âquivalent √† :
uv run python -m src.logs_pipeline.pipeline --source redis --once
```

**Sortie** :
```
üìä Pipeline de logs - Ex√©cution unique
===========================================
Source: redis
Elasticsearch: localhost:9200
Batch size: 100
-------------------------------------------
‚úÖ Collecte: 42 logs r√©cup√©r√©s
‚úÖ Filtrage: 38 logs filtr√©s
‚úÖ Indexation:
   - ml-api-logs: 42 documents
   - ml-api-message: 38 documents
   - ml-api-perfs: 38 documents
   - ml-api-top-func: 152 documents (4 par transaction)
===========================================
Dur√©e totale: 1.23s
```

### Mode 2 : Ex√©cution Continue

```bash
# Mode continu (toutes les 10 secondes)
make pipeline-continuous

# √âquivalent √† :
uv run python -m src.logs_pipeline.pipeline --source redis --continuous --interval 10
```

**Sortie** :
```
üîÑ Pipeline de logs - Mode continu (interval: 10s)
===========================================
[2025-11-22 10:30:00] ‚úÖ Batch #1: 42 logs index√©s
[2025-11-22 10:30:10] ‚úÖ Batch #2: 15 logs index√©s
[2025-11-22 10:30:20] ‚úÖ Batch #3: 0 logs (aucun nouveau)
[2025-11-22 10:30:30] ‚úÖ Batch #4: 23 logs index√©s
...
```

### Mode 3 : Avec Docker Compose

```bash
# Lancer Elasticsearch + Kibana
make pipeline-elasticsearch-up

# Attendre le d√©marrage (30s)
sleep 30

# Lancer le pipeline
make pipeline-continuous
```

### Mode 4 : Depuis Gradio

```bash
# Mode Gradio (HuggingFace Spaces)
uv run python -m src.logs_pipeline.pipeline --source gradio --once

# Avec URL personnalis√©e
GRADIO_URL=https://custom-space.hf.space uv run python -m src.logs_pipeline.pipeline --source gradio --once
```

## Monitoring

### Commandes Makefile

```bash
# Vider tous les index
make pipeline-clear-indexes

# Statistiques Elasticsearch
curl http://localhost:9200/_cat/indices?v

# Compter les documents
curl http://localhost:9200/ml-api-logs/_count
curl http://localhost:9200/ml-api-message/_count
curl http://localhost:9200/ml-api-perfs/_count
curl http://localhost:9200/ml-api-top-func/_count
```

### Kibana Dashboards

**Acc√®s** : http://localhost:5601

**Index Patterns √† cr√©er** :
1. `ml-api-logs*` - Tous les logs
2. `ml-api-message*` - Logs de pr√©dictions
3. `ml-api-perfs*` - M√©triques de performance
4. `ml-api-top-func*` - Profiling fonctions

**Visualisations recommand√©es** :

| Dashboard | Visualisations |
|-----------|----------------|
| **Vue d'ensemble** | Nombre de logs par heure, Distribution des niveaux (INFO/ERROR), Top 10 endpoints |
| **Pr√©dictions ML** | Distribution YES/NO, Features moyennes, Probabilit√©s (histogram), Drift de donn√©es |
| **Performance** | Latence (p50, p95, p99), CPU usage, M√©moire utilis√©e, Top fonctions co√ªteuses |
| **Erreurs** | Taux d'erreur, Types d'erreurs, Timeline des erreurs |

### Alertes Recommand√©es

| M√©trique | Seuil Warning | Seuil Critical | Action |
|----------|---------------|----------------|--------|
| Latence moyenne | > 100ms | > 200ms | V√©rifier le pool |
| Taux d'erreur | > 5% | > 10% | V√©rifier les logs |
| CPU usage | > 80% | > 95% | Scaler horizontalement |
| M√©moire | > 1GB | > 2GB | Optimiser le pool |

## Troubleshooting

### Probl√®me 1 : Pas de logs collect√©s

**Diagnostic** :
```bash
# V√©rifier Redis
redis-cli -h localhost -p 6379 LLEN api_logs

# V√©rifier Gradio
curl https://francoisformation-oc-project8.hf.space/logs_api?limit=10
```

**Solutions** :
- V√©rifier que l'API g√©n√®re des logs
- V√©rifier la connexion Redis/Gradio
- V√©rifier les variables d'environnement

### Probl√®me 2 : Erreurs d'indexation

**Diagnostic** :
```bash
# V√©rifier Elasticsearch
curl http://localhost:9200/_cluster/health

# V√©rifier les index
curl http://localhost:9200/_cat/indices?v
```

**Solutions** :
- V√©rifier qu'Elasticsearch est d√©marr√©
- V√©rifier le mapping des index
- Augmenter la taille du batch

### Probl√®me 3 : Doublons dans Elasticsearch

**Diagnostic** :
```bash
# Compter les documents
curl http://localhost:9200/ml-api-logs/_count
```

**Solutions** :
- V√©rifier la d√©duplication dans le collector
- Ajouter un champ `_id` unique (transaction_id)
- Nettoyer les index et r√©indexer

## Migration et Backup

### Export complet

```bash
python scripts/migrate_elasticsearch.py export --output ./backup
```

### Import complet

```bash
python scripts/migrate_elasticsearch.py import --input ./backup/backup_YYYYMMDD_HHMMSS
```

Documentation compl√®te : [ELASTIC.md](ELASTIC.md)

## R√©f√©rences

- [Architecture globale](ARCHITECTURE.md)
- [Documentation API](API_DOCUMENTATION.md)
- [M√©triques de performance](PERFORMANCE_METRICS.md)
- [Migration Elasticsearch](ELASTIC.md)
- [Code source pipeline](../src/logs_pipeline/README.md)

---

**Version** : 1.0.0
**Derni√®re mise √† jour** : 22 novembre 2025
**Projet** : OpenClassrooms MLOps - Projet 8
